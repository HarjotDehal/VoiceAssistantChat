<!DOCTYPE html>
<html>
<head>
    <title>Voice Assistant</title>
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='styles.css') }}">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
    @keyframes pulse-animation {
    0% {
        transform: scale(1);
    }
    50% {
        transform: scale(1.05);
    }
    100% {
        transform: scale(1);
    }
}

h4 {
    animation: pulse-animation 1s infinite alternate;
}
    </style>


</head>
<body>
    <h1 style="text-align: center;">Voice Assistant</h1>

    <h3 style="text-align: center;"> Built in Commands are any spoken messages which include "hello", "goodbye", "time", "weather", "joke", "quote" and "open" followed by any website name will open a website</h3>
    <h3 style="text-align: center;">Any other input will be given to ChatGPT!!!</h3>
    <h4   style="text-align: center; text-decoration: underline;animation: pulse-animation 1s infinite;"> If the Speaker doesn't automatically start speaking the replies to your inputs, hit the F12 key twice and it will work</h4>



    <h5   style="text-align: center; text-decoration: underline;"> If you dont speak for a little while, the microphone goes away due to google chrome. Refresh the page to keep testing </h5>

    <div class="container">
        <div class="voice-assistant">
            <div class="response" style="margin-top: 85px;">
<!-- 
<p class="response1">                Your Command shall appear here
</p>
<p class="response2">                Your Reply shall appear here
</p> -->
        Your Command and Response Shall Appear Here

            </div>
        </div>
        <img src="{{ url_for('static', filename='aee-unscreen.gif') }}" alt="Assistant" class="assistant-gif">
    </div>

<!-- 
    <button id="speak-button">Speak</button> Add the "Speak" button -->

    <script>
        
        $(document).ready(function() {
            function startListening() {
                var recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = false;

                recognition.onresult = function(event) {
                    var result = event.results[event.results.length - 1][0].transcript;
                    handleResult(result);
                };


                recognition.start();
            }

            function handleResult(result) {
                $.ajax({
                    url: "/process",
                    type: "POST",
                    contentType: "application/json",
                    data: JSON.stringify({query: result}),
                    success: function(response) {
                        if (response.startsWith("Opening")) {
                    // If response is related to opening a URL, open it in a new tab
                    window.open(response.substring(8), "_blank");
                } else if (response.startsWith("http")) {
                    // If response is a URL, open it in a new tab
                    window.open(response, "_blank");
                } else {
                            
                            
                            $(".response").text(response);
                            speak(response);
                }
                    }
                });
            }

            // $("#speak-button").on("click", function() {
            //     var responseText = $("#response").text();
            //     speak(responseText);
            // });

            function speak(text) {
                var synthesis = window.speechSynthesis;
                var utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 0.9;
                utterance.pitch = 1;
                synthesis.speak(utterance);
                console.log('hiii');
            }

            startListening();
        });
    </script>
</body>
</html>